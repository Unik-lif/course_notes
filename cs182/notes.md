## Slice 1
People tend to have multilingul model to translate many different lanuages to another lanuage, instead of some seperate ones

Researchers find:
- Imporved efficiency: Translating into and out of rare languages works better if the model is also trained on more common languages
- Zero-shot machine translation: you trained English to French, you trained French to Spainish, you can translate from English to Spanish with no examples

下面这是很有意思的现象，白俄罗斯语居然看上去可以是很像乌克兰语

Belarusian Examples: Less examples, more rely on other languages like Russian
- The mixture in between Russian/Belarusian 0.44- 0.46 looks like Ukarine!

Story => Representations of DL.
- How to find the "THOUGHTS" behind the languages
- 联觉信标

Handling such complex inputs requires representations => The power of deep learning lies in its ability to learn such representations automatically from "IDEAS" and "THOUGHTS"

## Slice 2
machine learning and deep learning
- machine learning: a function is a set of rules for transforming inputs into outputs, somtimes we can define the rules by hand (programming). Key idea: instead of implement rules, when the rules that describe how inputs map to outputs are complex and full of corner cases, provide data or examples might be a better Idea!

比如说给快乐小狗狗拍很多照片！

13:29